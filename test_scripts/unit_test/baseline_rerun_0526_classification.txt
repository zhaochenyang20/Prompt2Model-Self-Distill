INFO 05-27 00:12:12 llm_engine.py:72] Initializing an LLM engine with config: model='lmsys/vicuna-7b-v1.5', tokenizer='lmsys/vicuna-7b-v1.5', tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.float16, max_seq_len=4096, download_dir=None, load_format=auto, tensor_parallel_size=1, quantization=None, seed=0)
INFO 05-27 00:12:17 llm_engine.py:207] # GPU blocks: 7443, # CPU blocks: 2048
task1516 test notion== => 0.040625
task1529 test notion== => 0.06520307354555434
task1612 test notion== => 0.1469135802469136
task1615 test notion== => 0.0006176652254478073
task284 test notion== => 0.40930073516840487
task329 test notion== => 0.45132301547678483
task346 test notion== => 0.025478796169630644
