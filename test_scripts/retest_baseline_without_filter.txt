INFO 05-26 02:32:48 llm_engine.py:72] Initializing an LLM engine with config: model='lmsys/vicuna-7b-v1.5', tokenizer='lmsys/vicuna-7b-v1.5', tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.float16, max_seq_len=4096, download_dir=None, load_format=auto, tensor_parallel_size=1, quantization=None, seed=0)
INFO 05-26 02:32:53 llm_engine.py:207] # GPU blocks: 7443, # CPU blocks: 512


result
------------------------------------------------

0.3651320706520831

------------------------------------------------


INFO 05-26 02:36:42 llm_engine.py:72] Initializing an LLM engine with config: model='lmsys/vicuna-7b-v1.5', tokenizer='lmsys/vicuna-7b-v1.5', tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.float16, max_seq_len=4096, download_dir=None, load_format=auto, tensor_parallel_size=1, quantization=None, seed=0)
INFO 05-26 02:36:45 llm_engine.py:207] # GPU blocks: 7443, # CPU blocks: 512


result
------------------------------------------------

0.43093540845157

------------------------------------------------


INFO 05-26 02:38:44 llm_engine.py:72] Initializing an LLM engine with config: model='lmsys/vicuna-7b-v1.5', tokenizer='lmsys/vicuna-7b-v1.5', tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.float16, max_seq_len=4096, download_dir=None, load_format=auto, tensor_parallel_size=1, quantization=None, seed=0)
INFO 05-26 02:38:47 llm_engine.py:207] # GPU blocks: 7443, # CPU blocks: 512


result
------------------------------------------------

0.2842532841924298

------------------------------------------------


INFO 05-26 02:39:02 llm_engine.py:72] Initializing an LLM engine with config: model='lmsys/vicuna-7b-v1.5', tokenizer='lmsys/vicuna-7b-v1.5', tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.float16, max_seq_len=4096, download_dir=None, load_format=auto, tensor_parallel_size=1, quantization=None, seed=0)
INFO 05-26 02:39:05 llm_engine.py:207] # GPU blocks: 7443, # CPU blocks: 512


result
------------------------------------------------

0.4300258496285514

------------------------------------------------


INFO 05-26 02:40:23 llm_engine.py:72] Initializing an LLM engine with config: model='lmsys/vicuna-7b-v1.5', tokenizer='lmsys/vicuna-7b-v1.5', tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.float16, max_seq_len=4096, download_dir=None, load_format=auto, tensor_parallel_size=1, quantization=None, seed=0)
INFO 05-26 02:40:26 llm_engine.py:207] # GPU blocks: 7443, # CPU blocks: 512


result
------------------------------------------------

0.2140625

------------------------------------------------


INFO 05-26 02:40:56 llm_engine.py:72] Initializing an LLM engine with config: model='lmsys/vicuna-7b-v1.5', tokenizer='lmsys/vicuna-7b-v1.5', tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.float16, max_seq_len=4096, download_dir=None, load_format=auto, tensor_parallel_size=1, quantization=None, seed=0)
INFO 05-26 02:41:00 llm_engine.py:207] # GPU blocks: 7443, # CPU blocks: 512


result
------------------------------------------------

0.09769484083424808

------------------------------------------------


INFO 05-26 02:44:59 llm_engine.py:72] Initializing an LLM engine with config: model='lmsys/vicuna-7b-v1.5', tokenizer='lmsys/vicuna-7b-v1.5', tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.float16, max_seq_len=4096, download_dir=None, load_format=auto, tensor_parallel_size=1, quantization=None, seed=0)
INFO 05-26 02:45:03 llm_engine.py:207] # GPU blocks: 7443, # CPU blocks: 512


result
------------------------------------------------

0.006176652254478073

------------------------------------------------


INFO 05-26 02:45:52 llm_engine.py:72] Initializing an LLM engine with config: model='lmsys/vicuna-7b-v1.5', tokenizer='lmsys/vicuna-7b-v1.5', tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.float16, max_seq_len=4096, download_dir=None, load_format=auto, tensor_parallel_size=1, quantization=None, seed=0)
INFO 05-26 02:45:55 llm_engine.py:207] # GPU blocks: 7443, # CPU blocks: 512


result
------------------------------------------------

0.23589615576635048

------------------------------------------------


INFO 05-26 02:51:24 llm_engine.py:72] Initializing an LLM engine with config: model='lmsys/vicuna-7b-v1.5', tokenizer='lmsys/vicuna-7b-v1.5', tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.float16, max_seq_len=4096, download_dir=None, load_format=auto, tensor_parallel_size=1, quantization=None, seed=0)
INFO 05-26 02:51:28 llm_engine.py:207] # GPU blocks: 7443, # CPU blocks: 512


result
------------------------------------------------

0.23050615595075238

------------------------------------------------


INFO 05-26 02:57:13 llm_engine.py:72] Initializing an LLM engine with config: model='lmsys/vicuna-7b-v1.5', tokenizer='lmsys/vicuna-7b-v1.5', tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.float16, max_seq_len=4096, download_dir=None, load_format=auto, tensor_parallel_size=1, quantization=None, seed=0)
INFO 05-26 02:57:17 llm_engine.py:207] # GPU blocks: 7443, # CPU blocks: 512


result
------------------------------------------------

0.8319083447332422

------------------------------------------------


INFO 05-26 03:09:52 llm_engine.py:72] Initializing an LLM engine with config: model='lmsys/vicuna-7b-v1.5', tokenizer='lmsys/vicuna-7b-v1.5', tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.float16, max_seq_len=4096, download_dir=None, load_format=auto, tensor_parallel_size=1, quantization=None, seed=0)
INFO 05-26 03:09:55 llm_engine.py:207] # GPU blocks: 7443, # CPU blocks: 512


result
------------------------------------------------

0.5141975308641975

------------------------------------------------


